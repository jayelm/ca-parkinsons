\documentclass[letterpaper,12pt]{article}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bm}
\usepackage{numprint}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
% Random packages from
% http://tex.stackexchange.com/questions/50070/landscape-figure-in-latex
% Necessary for sideways pictures
\usepackage{wrapfig}
\usepackage{lscape}
\usepackage{rotating}
\usepackage{epstopdf}
\usepackage{tablefootnote}
% for word wrap verbatim
\usepackage{listings}
\lstset{
   breaklines=true,
   basicstyle=\ttfamily}
% \pagestyle{fancy}
% \lhead{Jesse Mu}
% \rhead{Foo}
\graphicspath{ {../figures/} }
% Or this, if run from main folder
% \graphicspath{ {./figures/} }


\begin{document}

\title{Cluster Analysis: Identifying Parkinson's Disease Subtypes}
\date{Wednesday, June 10}
\author{Jesse Mu}
\maketitle

\section{Preprocessing}

\emph{NOTE: as of 2015-07-22 the statistics in this pdf are likely to not be up
to date, since not all of them are necessary anymore and updating them takes
time. Recalculate statistics if they'll be used in a further writeup.}

\subsection{Dataset Description}
951 subjects, 145 metrics, collected 15-4-2012 from Pablo Martinez Mart\'in. Only
19 features used for clustering and/or interpretation.  50 subjects with
missing values of the features to be used in clustering (brought down to 901).
Imputation may be a good idea later on.

\subsection{Selected Features}

Combination of non-motor scale (NMS) symptoms and standard motor symptoms.

\begin{table}[h]
  \centering
  \begin{tabular}{l|l|l|l}
    Name & Type & Format & Description \\
    \hline
    nms\_d1 & byte & \%8.0g & cardiovascular \\
    nms\_d2 & byte & \%8.0g & sleep/fatigue \\
    nms\_d3 & byte & \%8.0g & mood/cognition \\
    nms\_d4 & byte & \%8.0g & percep/hallucinations \\
    nms\_d5 & byte & \%8.0g & attention/memory \\
    nms\_d6 & byte & \%8.0g & gastrointestinal \\
    nms\_d7 & byte & \%8.0g & urinary \\
    nms\_d8 & byte & \%8.0g & sexual function \\
    nms\_d9 & byte & \%8.0g & miscellaneous \\
    tremor & float & \%9.0g & tremor \\
    bradykin & float & \%9.0g & bradykinesia\tablefootnote{Impaired ability to
    adjust the body's position.} \\
    rigidity & float & \%9.0g & rigidity \\
    axial & float & \%9.0g & axial\tablefootnote{Issues affecting the middle of
    the body.} \\
    pigd & float & \%9.0g & postural instability and gait difficulty \\
  \end{tabular}
  \caption{Selected Features and Details}
  \label{tab:selected-features}
\end{table}

\begin{table}[h]
  \centering
  \begin{tabular}{l|l|l|l}
  Name  &       $\mu$ & $\sigma$ & min-max \\
         \hline
nms\_d1&   1.73&  3.35&   0-24 \\
nms\_d2&   8.75&  8.70&   0-48 \\
nms\_d3&   8.68& 11.55&   0-60 \\
nms\_d4&   1.64&  3.86&   0-33 \\
nms\_d5&   5.42&  7.43&   0-36 \\
nms\_d6&   5.53&  6.79&   0-36 \\
nms\_d7&   8.08&  8.94&   0-36 \\
nms\_d8&   3.52&  5.97&   0-24 \\
nms\_d9&   7.13&  7.79&   0-48 \\
tremor&   2.59&  2.58&   0-12 \\
bradykin& 2.40&  1.41&   0-6 \\
rigidity& 2.24&  1.36&   0-6 \\
axial&    3.25&  2.68&   0-12 \\
pigd&     3.31&  2.71&   0-12 \\
  \end{tabular}
  \caption{Descriptive Statistics}
  \label{tab:descriptive-statistics}
\end{table}

\subsection{Dimensionality Reduction: PCA}

May not be useful? If we're trying to identify \emph{clinically} relevant
features, merging them may not be a good idea. Regardless, Figure~\ref{fig:pca}
shows results of preliminary PCA.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{pca.pdf}
  \caption{PCA Analysis}
  \label{fig:pca}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{pca-eigenvalues.pdf}
  \caption{Scree test: eigenvalues by factor}
  \label{fig:pca-eigenvalues}
\end{figure}

Figure~\ref{fig:pca-eigenvalues} shows scree test elbow occurs around 2 or 2 or
.4 Also, eigenvalues $1-5 > 1$.

\clearpage
\section{$k$-means}
\subsection{Identifying optimal number of clusters}

\subsubsection{WSS Error Scree Test}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{kmeans-wss-error.pdf}
  \caption{Scree test: WSS error by cluster size}
  \label{fig:kmeans-wss-error}
\end{figure}

Figure~\ref{fig:kmeans-wss-error} shows no optimal elbow in scree test! Maybe 2-3?

\subsubsection{Gap Statistic}

Optimal cluster is the local maximum of the gap statistic, but it appears to be
consistently increasing in Figure~\ref{fig:gap-statistic}.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{gap-statistic.pdf}
  \caption{Gap statistic by cluster size}
  \label{fig:gap-statistic}
\end{figure}

\subsubsection{Average Silhouette Width}

Figure~\ref{fig:asw} shows average silhouette width as being consistently under
0.25 for all clusters, implying the data is not well structured.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{asw.pdf}
  \caption{Average silhouette width by cluster size}
  \label{fig:asw}
\end{figure}

% \subsubsection{\texttt{NbClust} package}

\subsection{Cluster statistics}
% CLUSTERS: 2
% ================================
% Sizes: 229 672
% WithinSS: 6117.986 7695.411
% Sum WithinSS: 13813.4
% CLUSTERS: 3
% ================================
% Sizes: 333 134 434
% WithinSS: 4669.037 4009.387 4153.892
% Sum WithinSS: 12832.32
% CLUSTERS: 4
% ================================
% Sizes: 79 394 275 153
% WithinSS: 2366.585 3356.709 3454.142 2879.508
% Sum WithinSS: 12056.94
\begin{table}[h]
  \centering
  \begin{tabular}{l|l|l|l}
    $k$ & $n$ & Within SS & sum(Within SS) \\
    \hline
    2 & 229/672 & 6118/7695 & 13813 \\
    3 & 333/134/434 & 4669/40009/4154 & 12832 \\
    4 & 79/394/275/153 & 2367/3357/3454/2880  & 12057 \\
  \end{tabular}
  \caption{Cluster statistics}
  \label{tab:cluster-statistics}
\end{table}

\subsection{Silhouette plots}

Available in
Figures~\ref{fig:kmeans-silhouette-2},~\ref{fig:kmeans-silhouette-3},
and~\ref{fig:kmeans-silhouette-4}. Note: constructed with standardized
$z$-score data.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{kmeans-silhouette-2.pdf}
  \caption{$k$-means cluster silhouette plot, $k = 2$}
  \label{fig:kmeans-silhouette-2}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{kmeans-silhouette-3.pdf}
  \caption{$k$-means cluster silhouette plot, $k = 3$}
  \label{fig:kmeans-silhouette-3}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{kmeans-silhouette-4.pdf}
  \caption{$k$-means cluster silhouette plot, $k = 4$}
  \label{fig:kmeans-silhouette-4}
\end{figure}

\subsection{Decision trees based on clusters}
% seed = 911
% CLUSTERS: 2
% ================================
% Complexity Parameter: 0.02183406
% 10-fold CV error: 0.1132075
% Root node error: 0.254162
% CLUSTERS: 3
% ================================
% Complexity Parameter: 0.01070664
% 10-fold CV error: 0.190899
% Root node error: 0.518313
% CLUSTERS: 4
% ================================
% Complexity Parameter: 0.01
% 10-fold CV error: 0.2552719
% Root node error: 0.5627081
\begin{table}[h]
  \centering
  \begin{tabular}{l|l|l|l|l|l}
    $k$ & CP\tablefootnote{Complexity Parameter} & CV Xerror\tablefootnote{10-fold cross
    validation} & Root Feature &
    Root Error & Figure \\
    \hline
    2 & 0.0218 & 0.113 & axial $\geq$ 4.5 & 0.254 & Figure~\ref{fig:kmeans-dtree-2} \\
    3 & 0.0107 & 0.191 & pigd $\geq$ 2.5 & 0.518 & Figure~\ref{fig:kmeans-dtree-3} \\
    4 & 0.0100 & 0.255 & pigd $<$ 2.5 & 0.563 & Figure~\ref{fig:kmeans-dtree-4} \\
  \end{tabular}
  \caption{$k$-kmeans decision trees statistics}
  \label{tab:k-means-dtrees}
\end{table}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{dtree-kmeans-pruned-unscaled-2.pdf}
  \caption{Decision Tree from $k$-means clustering, 2 clusters}
  \label{fig:kmeans-dtree-2}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{dtree-kmeans-pruned-unscaled-3.pdf}
  \caption{Decision Tree from $k$-means clustering, 3 clusters}
  \label{fig:kmeans-dtree-3}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{dtree-kmeans-pruned-unscaled-4.pdf}
  \caption{Decision Tree from $k$-means clustering, 4 clusters}
  \label{fig:kmeans-dtree-4}
\end{figure}

\subsection{Interpretation of Clusters}

\subsubsection{Cluster summaries}

Available in
Figures~\ref{fig:kmeans-summaries-2},~\ref{fig:kmeans-summaries-3},
and~\ref{fig:kmeans-summaries-4}. Error bar is standard error.

\subsubsection{Interpretation}

$k = 2$ seems too basic. Cluster is organized solely by severity - all
symptoms, including motor and nonmotor, are higher in severity in cluster 1,
and lower in cluster 2. Quite consistently, groups in cluster 1 are generally
of slightly higher age and pd duration.

$k = 3$ seems like a further development of $k = 2$, where clusters are simply
organized by linearly increasing severity.

$k = 4$ is where it gets interesting.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{kmeans-summaries-2.pdf}
  \caption{Cluster Summaries, $k = 2$}
  \label{fig:kmeans-summaries-2}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{kmeans-summaries-3.pdf}
  \caption{Cluster Summaries, $k = 3$}
  \label{fig:kmeans-summaries-3}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{kmeans-summaries-4.pdf}
  \caption{Cluster Summaries, $k = 4$}
  \label{fig:kmeans-summaries-4}
\end{figure}

\subsubsection{Statistical Significance Tests, $k = 4$}
Using one-way ANOVA for multiple means, we reject the null
hypothesis that the means are the same with $p < 0.05$ for every variable
\emph{except} \texttt{pdonset}.

\subsubsection{Ranked Features}

\begin{table}[h]
  \centering
  \caption{Features ranked by information gain}
  \label{tab:info_gain}
  \begin{tabular}{l|l}
    variable & information gain \\
    \hline
    axial      & 0.20640691 \\
    cisitot      & 0.20008571 \\
    pigd      & 0.18193982 \\
    nms\_d2      & 0.13178572 \\
    nms\_d9      & 0.12116024 \\
    bradykin      & 0.11966097 \\
    nms\_d3      & 0.09421859 \\
    rigidity      & 0.09260628 \\
    nms\_d5      & 0.07579997 \\
    nms\_d4      & 0.07438784 \\
    nms\_d6      & 0.06620599 \\
    nms\_d7      & 0.05574956 \\
    nms\_d1      & 0.05509838 \\
    tremor      & 0.04140473 \\
    nms\_d8      & 0.03786173 \\
    durat\_pd      & 0.02794420 \\
    age      & 0.00000000 \\
    sex      & 0.00000000 \\
    pdonset      & 0.00000000 \\
  \end{tabular}
\end{table}


\clearpage
\section{Affinity Propagation}

\subsection{Clustering}

Package \texttt{apcluster} was used. Distance matrix was the negative euclidean
squared distance ($r = 2$).

AP with input preferences minimized ($q = 0$) resulted in 8 clusters.
With the standard median input preferences ($q = 0.5$), algorithm failed to
converge with default parameters. Even setting damping factor to 0.98, maximum
iterations to 10000, and convergence iterations to 1000 failed to converge.
Might need to try a longer run.

\emph{However}, given that input preferences control how many clusters are
found, I don't think it's very useful to have some dozen clusters running
around.

\subsubsection{Silhouette Plots}

Silhouette plot in Figure~\ref{fig:ap-silhouette} looks pretty weak, really.
Tons of overlap between the clusters.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{ap-silhouette.pdf}
  \caption{AP silhouette plot, $k = 8$}
  \label{fig:ap-silhouette}
\end{figure}

\clearpage
\section{Hierarchical Clustering}

\subsection{Clustering}

Four dissimilarity methods were used with a euclidean distance matrix.
Dendrograms available in Figure~\ref{fig:hc-dendrograms}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{hc-dendrograms.pdf}
  \caption{Dendrograms}
  \label{fig:hc-dendrograms}
\end{figure}

\subsection{Cutting Trees}
\begin{table}[h]
  \centering
  \begin{tabular}{l|l|l|l}
    Method & Condition & n & Figure \\
    \hline
    Complete & $k = 4$ & 4 (790/81/18/12) & ~\ref{fig:hc-summaries-complete-k4} \\
    Complete & \texttt{dynamicTreeCut}\tablefootnote{Package \texttt{dynamicTreeCut} in R (Langfelder P,
  Zhang B, Horvath S (2007)). Hybrid method, minimum cluster selection
parameters} & 13 (255/99/77/64/62/58/56/46/44/41/37/32/30) &
    ~\ref{fig:hc-summaries-complete-dynamic} \\
    Ward & $k = 4$ & 4 (200/237/263/201) & ~\ref{fig:hc-summaries-ward-D-k4} \\
    Ward & $h = 100$ & 3 (437/263/201) &
    ~\ref{fig:hc-summaries-ward-D-h100} \\
  \end{tabular}
  \caption{Clusters from Tree Cutting}
  \label{tab:tree-cutting}
\end{table}

\subsection{Interpretation}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{hc-summaries-complete-k4.pdf}
  \caption{Using maximum (complete linkage) dissimilarity, cutting tree for $k = 4$}
  \label{fig:hc-summaries-complete-k4}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{hc-summaries-complete-dynamic.pdf}
  \caption{Using maximum (complete linkage) dissimilarity, cutting tree
    dynamically}
  \label{fig:hc-summaries-complete-dynamic}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{hc-summaries-ward-D-k4.pdf}
  \caption{Using Ward (1963) dissimilarity, cutting tree for $k = 4$}
  \label{fig:hc-summaries-ward-D-k4}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{hc-summaries-ward-D-h100.pdf}
  \caption{Using Ward (1963) dissimilarity, cutting tree at $h = 100$}
  \label{fig:hc-summaries-ward-D-h100}
\end{figure}


\subsection{Interpretation}

Cluster sizes are available in Table~\ref{tab:ap-cluster-sizes}

\begin{table}[h]
  \centering
  \begin{tabular}{l|l}
  Cluster & Size \\
  \hline
  1 & 63 \\
  2 & 53 \\
  3 & 85 \\
  4 & 122 \\
  5 & 48 \\
  6 & 126 \\
  7 & 123 \\
  8 & 102 \\
  9 & 166 \\
  10 & 13 \\
  \end{tabular}
  \caption{AP Cluster Sizes}
  \label{tab:ap-cluster-sizes}
\end{table}

Boxplot summary of clusters available in Figure~\ref{fig:ap-summaries}.
\textbf{Discussion forthcoming.}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{ap-summaries.pdf}
  \caption{AP Boxplot Summaries}
  \label{fig:ap-summaries}
\end{figure}

\section{Biclustering}

Used BCBimax clustering algorithm. Clusters seem quite sparse.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{biclust-heatmaps-16.pdf}
  \caption{Biclustering heatmaps $N = 16$}
  \label{fig:biclust-heatmaps-16}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{biclust-bubbleplot-16.pdf}
  \caption{Bubbleplot $N = 16$}
  \label{fig:bubbleplot-16}
\end{figure}

\section{Subspace clustering}

% TODO: Wat.

\section{Bayesian Networks}

\end{document}
